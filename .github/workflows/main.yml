name: Collect Proxies
on:
  schedule:
    - cron: '0 * * * *'
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Collect and Clean Vless
        run: |
          SOURCE_FILE=$(ls | grep -i "links.txt" | head -n 1)
          if [ -z "$SOURCE_FILE" ]; then exit 1; fi
          
          rm -f all_proxies.txt temp.txt filtered.txt
          touch temp.txt
          
          # 1. Скачиваем всё
          while IFS= read -r url || [ -n "$url" ]; do
            clean_url=$(echo "$url" | tr -d '\r' | xargs)
            [[ -z "$clean_url" || "$clean_url" == "#"* ]] && continue
            curl -sL --max-time 15 "$clean_url" >> temp.txt
            echo "" >> temp.txt
          done < "$SOURCE_FILE"
          
          # 2. Декодируем URL-мусор (убираем %25 и прочее)
          # Оставляем только строки, начинающиеся на vless://
          # Очищаем от мусора в конце и начале
          sed -i 's/vless:/\nvless:/g' temp.txt
          grep -a "vless://" temp.txt | sed 's/.*vless:\/\//vless:\/\//' | cut -d' ' -f1 | cut -d'"' -f1 | cut -d"'" -f1 > filtered.txt
          
          # 3. Убираем дубликаты и лимит 30 000
          sort -u filtered.txt | grep -v "%25%25" | head -n 30000 > all_proxies.txt
          
          rm -f temp.txt filtered.txt

      - name: Commit and Push
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add all_proxies.txt
          git commit -m "Fix encoding and update list $(date)" || exit 0
          git push
